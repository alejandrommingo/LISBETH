# Plan Maestro: An√°lisis de Yape como Actor Social

Este documento establece la hoja de ruta integral para la investigaci√≥n "De la billetera m√≥vil al actor social", detallando roles, fases y tareas espec√≠ficas para garantizar una ejecuci√≥n robusta y cient√≠ficamente v√°lida.

## 1. Definici√≥n de Roles y Responsabilidades

Para asegurar la calidad en cada etapa del pipeline, definimos los siguientes roles l√≥gicos (que pueden ser ejecutados por una o varias personas/agentes):

### üõ†Ô∏è Role: Data Engineer (Ingeniero de Datos)
**Responsabilidad**: Garantizar la disponibilidad, calidad y completitud del corpus de noticias.
*   Mantenimiento de `Lisbeth News Harvester`.
*   Implementaci√≥n de soporte para m√∫ltiples queries.
*   Limpieza y preprocesamiento de texto (normalizaci√≥n, eliminaci√≥n de ruido).
*   Gesti√≥n del almacenamiento de datos y embeddings.

### üß† Role: NLP Engineer (Ingeniero de PNL)
**Responsabilidad**: Transformar texto en representaciones matem√°ticas precisas.
*   Selecci√≥n y validaci√≥n de modelos de lenguaje (BERT/RoBERTa).
*   Implementaci√≥n del pipeline de extracci√≥n de embeddings contextuales (Token-level).
*   Fine-tuning de modelos (si fuera necesario por especificidad del dominio).

### üìê Role: Data Scientist (Cient√≠fico de Datos)
**Responsabilidad**: Modelado matem√°tico y c√°lculo de m√©tricas.
*   Implementaci√≥n de algoritmos de reducci√≥n de dimensionalidad (PCA/SVD).
*   Ejecuci√≥n de An√°lisis Paralelo de Horn y Bootstrapping para estabilidad.
*   C√°lculo de m√©tricas complejas (Deriva Sem√°ntica, Entrop√≠a, Proyecci√≥n).

### üîé Role: Researcher (Investigador Principal)
**Responsabilidad**: Definici√≥n te√≥rica e interpretaci√≥n de resultados.
*   Definici√≥n de "Vectores Ancla" (listas de palabras semilla para cada frame).
*   Validaci√≥n sem√°ntica de los subespacios hallados.
*   Redacci√≥n de hallazgos y vinculaci√≥n con la teor√≠a.

---

## 2. Plan de Ejecuci√≥n Detallado

### Fase 1: Expansi√≥n y Refinamiento de Datos (Data Engineer)
**Objetivo**: Capturar todas las variaciones de la marca para no perder data relevante.

*   [x] **Implementar Multi-Query Support**: Modificar el harvester para aceptar listas de keywords (`["Yape", "Yapear", "Yapeo", "Yapame"]`).
*   [x] **Implementar Daily Chunking**: Modificar el harvester para que **siempre** divida las consultas en intervalos diarios (d√≠a a d√≠a) para asegurar la m√°xima exhaustividad, independientemente del rango total.
*   [x] **Soluci√≥n Ligera para Renderizado JS**: Implementar un mecanismo (ej. Playwright o similar optimizado) para extraer texto de medios con Client-Side Rendering (La Rep√∫blica, etc.) que actualmente devuelven "200 OK" pero sin contenido. **Cr√≠tico antes de avanzar**.
*   [x] **Recolecci√≥n Hist√≥rica Completa (Re-run)**: Ejecutar barrido **1 Enero 2020 - 1 Enero 2021** con Daily Chunking y soporte JS.

### Fase 2: Infraestructura NLP (NLP Engineer)
**Objetivo**: Convertir el corpus en una base de datos de vectores contextuales robustos.

*   [ ] **Selecci√≥n de Modelo Principal**: Utilizar `PlanTL-GOB-ES/roberta-large-bne` (Encoder Bidireccional SOTA en espa√±ol).
    *   **Modelo de Contraste**: Usar `bertin-project/bertin-roberta-base-spanish` para validar robustez.
    *   **Nota**: Se descarta GPT (Decoder) por inadecuaci√≥n para representaci√≥n sem√°ntica bidireccional.
*   [ ] **Adaptaci√≥n al Dominio (DAPT)**: Realizar *Continued Pretraining* del modelo sobre el corpus de prensa peruana para mejorar la representaci√≥n de terminolog√≠a local ("Yapear", "Plin").
*   [ ] **Pipeline de Tokenizaci√≥n**: Implementar estrategia de **Subword Pooling** (promedio de sub-tokens) para manejar correctamente la fragmentaci√≥n (ej. `['Yape', '##ar']` -> `Yapear`).
*   [ ] **Extracci√≥n de Embeddings**: Generar tensores para cada ocurrencia de la marca.
    *   **Estrategia**: Concatenar √∫ltimas 4 capas (o investigar pen√∫ltima) + Normalizaci√≥n (Whitening/Centering).
*   [ ] **Almacenamiento**: Guardar los vectores con metadatos (fecha, medio, oraci√≥n original) en formato eficiente (ej. Parquet).

### Fase 3: An√°lisis de Subespacios (Data Scientist)
**Objetivo**: Modelar la evoluci√≥n sem√°ntica.

*   [ ] **Segmentaci√≥n Temporal**: Implementar **Ventanas Deslizantes** (Rolling Windows) para suavizar la deriva y reducir ruido (ej. Enero-Marzo, Febrero-Abril).
*   [ ] **An√°lisis de Dimensionalidad**: An√°lisis Paralelo de Horn + Bootstrap para determinar $k$ estable.
*   [ ] **Construcci√≥n de Subespacios**: Aplicar SVD a los vectores centrados/normalizados de cada ventana.
*   [ ] **C√°lculo de M√©tricas y Estabilidad**:
    *   *Grassmannian Distance* con intervalos de confianza (Bootstrap).
    *   *Semantic Volume* (Entrop√≠a).
    *   *Frame Projection* (Proyecci√≥n de Contextual Anchors).

### Fase 4: Interpretaci√≥n y Visualizaci√≥n (Researcher + Data Scientist)
**Objetivo**: Traducir n√∫meros a narrativa sociol√≥gica.

*   [ ] **Definici√≥n de Anclas**: Implementar **Estrategia H√≠brida**:
    *   *Baseline*: Vectores est√°ticos (Capa 0) de las keywords.
    *   *Contextual*: Centroides de "Oraciones Protot√≠picas" (del archivo `data/dimensiones_ancla.json`) procesadas por el modelo (√∫ltimas 4 capas).
*   [ ] **Validaci√≥n ("Ground Truth")**: Etiquetado manual de un subconjunto de datos para validar alineamiento de frames y valencia.
*   [ ] **Visualizaci√≥n Evolutiva**: Graficar m√©tricas con bandas de error (IC).
*   [ ] **Redacci√≥n de Resultados**: Integrar hallazgos validando hip√≥tesis.

---

## 3. Pr√≥ximos Pasos Inmediatos (Sprint Actual)

1.  **Data Engineer**: Actualizar `Lisbeth` para soportar m√∫ltiples keywords (ej. "Yape", "Yapear").
2.  **Researcher**: Validar la lista de variantes de la marca a rastrear.
