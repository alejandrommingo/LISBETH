# Plan Maestro: An√°lisis de Yape como Actor Social

Este documento establece la hoja de ruta integral para la investigaci√≥n "De la billetera m√≥vil al actor social", detallando roles, fases y tareas espec√≠ficas para garantizar una ejecuci√≥n robusta y cient√≠ficamente v√°lida.

## 1. Definici√≥n de Roles y Responsabilidades

Para asegurar la calidad en cada etapa del pipeline, definimos los siguientes roles l√≥gicos (que pueden ser ejecutados por una o varias personas/agentes):

### üõ†Ô∏è Role: Data Engineer (Ingeniero de Datos)
**Responsabilidad**: Garantizar la disponibilidad, calidad y completitud del corpus de noticias.
*   Mantenimiento de `Lisbeth News Harvester`.
*   Implementaci√≥n de soporte para m√∫ltiples queries.
*   Limpieza y preprocesamiento de texto (normalizaci√≥n, eliminaci√≥n de ruido).
*   Gesti√≥n del almacenamiento de datos y embeddings.

### üß† Role: NLP Engineer (Ingeniero de PNL)
**Responsabilidad**: Transformar texto en representaciones matem√°ticas precisas.
*   Selecci√≥n y validaci√≥n de modelos de lenguaje (BERT/RoBERTa).
*   Implementaci√≥n del pipeline de extracci√≥n de embeddings contextuales (Token-level).
*   Fine-tuning de modelos (si fuera necesario por especificidad del dominio).

### üìê Role: Data Scientist (Cient√≠fico de Datos)
**Responsabilidad**: Modelado matem√°tico y c√°lculo de m√©tricas.
*   Implementaci√≥n de algoritmos de reducci√≥n de dimensionalidad (PCA/SVD).
*   Ejecuci√≥n de An√°lisis Paralelo de Horn y Bootstrapping para estabilidad.
*   C√°lculo de m√©tricas complejas (Deriva Sem√°ntica, Entrop√≠a, Proyecci√≥n).

### üîé Role: Researcher (Investigador Principal)
**Responsabilidad**: Definici√≥n te√≥rica e interpretaci√≥n de resultados.
*   Definici√≥n de "Vectores Ancla" (listas de palabras semilla para cada frame).
*   Validaci√≥n sem√°ntica de los subespacios hallados.
*   Redacci√≥n de hallazgos y vinculaci√≥n con la teor√≠a.

---

## 2. Plan de Ejecuci√≥n Detallado

### Fase 1: Expansi√≥n y Refinamiento de Datos (Data Engineer)
**Objetivo**: Capturar todas las variaciones de la marca para no perder data relevante.

*   [x] **Implementar Multi-Query Support**: Modificar el harvester para aceptar listas de keywords (`["Yape", "Yapear", "Yapeo", "Yapame"]`).
*   [x] **Implementar Daily Chunking**: Modificar el harvester para que **siempre** divida las consultas en intervalos diarios (d√≠a a d√≠a) para asegurar la m√°xima exhaustividad, independientemente del rango total.
*   [x] **Soluci√≥n Ligera para Renderizado JS**: Implementar un mecanismo (ej. Playwright o similar optimizado) para extraer texto de medios con Client-Side Rendering (La Rep√∫blica, etc.) que actualmente devuelven "200 OK" pero sin contenido. **Cr√≠tico antes de avanzar**.
*   [x] **Recolecci√≥n Hist√≥rica Completa (Re-run)**: Ejecutar barrido **1 Enero 2020 - 1 Enero 2021** con Daily Chunking y soporte JS.

### Fase 2: Infraestructura NLP (NLP Engineer)
**Objetivo**: Convertir el corpus en una base de datos de vectores contextuales robustos.

*   [x] **Selecci√≥n de Modelo Principal**: Utilizar `PlanTL-GOB-ES/roberta-large-bne` (Encoder Bidireccional SOTA en espa√±ol).
    *   **Modelo de Contraste**: Usar `bertin-project/bertin-roberta-base-spanish` para validar robustez.
    *   **Nota**: Se descarta GPT (Decoder) por inadecuaci√≥n para representaci√≥n sem√°ntica bidireccional.
*   [x] **Adaptaci√≥n al Dominio (DAPT)**: Realizar *Continued Pretraining* del modelo sobre el corpus de prensa peruana para mejorar la representaci√≥n de terminolog√≠a local ("Yapear", "Plin").
*   [x] **Pipeline de Tokenizaci√≥n**: Implementar estrategia de **Subword Pooling** (promedio de sub-tokens) para manejar correctamente la fragmentaci√≥n (ej. `['Yape', '##ar']` -> `Yapear`).
*   [x] **Extracci√≥n de Embeddings**: Generar tensores para cada ocurrencia de la marca.
    *   **Estrategia**: Concatenar √∫ltimas 4 capas (o investigar pen√∫ltima) + Normalizaci√≥n (Whitening/Centering).
*   [x] **Almacenamiento**: Guardar los vectores con metadatos (fecha, medio, oraci√≥n original) en formato eficiente (ej. Parquet).

### Fase 3: An√°lisis de Subespacios Sem√°nticos (En Progreso)
**Objetivo**: Modelar la evoluci√≥n del significado de la marca a lo largo del tiempo mediante t√©cnicas algebraicas.

#### Sub-fase 3.1: Estrategia de Segmentaci√≥n Temporal (Data Scientist)
**Objetivo**: Preparar los datos para un an√°lisis evolutivo robusto, evitando el ruido de las fluctuaciones diarias.
*   [x] **Implementar Rolling Windows**: Crear generador de ventanas deslizantes configurables (ej. Tama√±o: 3 meses, Paso: 1 mes) para suavizar tendencias.
*   [x] **Filtrado Din√°mico de Vocabulario**: Asegurar que solo t√©rminos relevantes y persistentes en la ventana temporal sean considerados (min_frequency per window).
*   [x] **Validaci√≥n de Densidad**: Verificar que cada ventana tenga suficiente densidad de "keywords" para un an√°lisis estad√≠sticamente significativo.

#### Sub-fase 3.2: An√°lisis de Estabilidad y Dimensionalidad (Data Scientist)
**Objetivo**: Determinar matem√°ticamente cu√°ntas dimensiones ($k$) son necesarias para representar la realidad latente sin sobreajuste.
*   [x] **An√°lisis Paralelo de Horn**: Implementar test de permutaci√≥n para distinguir se√±al de ruido aleatorio.
*   [x] **Bootstrapping de Estabilidad**: Evaluar la robustez de los autovalores mediante remuestreo con reemplazo.
*   [x] **Selecci√≥n de $k$ √ìptimo**: Definir criterio de corte autom√°tico para cada ventana temporal.

## 3.3 Subspace Construction (Data Scientist)
- [x] **Architecture Refactor**: Split into `scripts/run_phase3_pipeline.py` (CLI) and `notebooks/phase3_analysis.ipynb` (Viewer).
- [x] Implement SVD decomposition on centered embeddings <!-- id: 45 -->
- [x] Implement Orthogonal Procrustes for temporal alignment <!-- id: 46 -->
- [x] Validate alignment stability with synthetic data <!-- id: 47 -->

## 3.4 Sociological Metrics (Researcher + Data Scientist)
- [x] **Methodology Upgrade**: Implement **Gram-Schmidt Orthogonalization** for Anchors (`metrics.py`).
- [x] Calculate Semantic Drift (Cosine Distance $t$ vs $t+1$) <!-- id: 47 -->
- [x] Calculate Theoretical Projections (Heatmap of Basis vs Orthogonal Anchors) <!-- id: 48 -->
- [x] Calculate Semantic Entropy (Volume of meaning) <!-- id: 49 -->
la "ambig√ºedad" o "riqueza" del significado.
*   [ ] **Proyecci√≥n de Marcos (Frame Projection)**: Proyectar los vectores de la marca sobre los ejes definidos por las Anclas Contextuales (Confianza, Inclusi√≥n, Riesgo) extra√≠das en Fase 2.

### Fase 4: Interpretaci√≥n y Creaci√≥n de Reporte Acad√©mico (Researcher + Data Scientist)
**Objetivo**: Sintetizar todo el proceso investigativo en un documento unificado de alto impacto cient√≠fico (tipo Nature/Science Paper).

#### Sub-fase 4.1: Dise√±o del Reporte Integral
*   [ ] **Estructura del Notebook Acad√©mico**: Crear `academic/Reporte_Integral_TFM.ipynb` con secciones: Abstract, Intro, Metodolog√≠a (Data & Model), Resultados, Discusi√≥n.
*   [ ] **Integraci√≥n Te√≥rica**: Incorporar resumen procesado de `INTRO_TFM.md` (Marco te√≥rico: Marca como actor social).
*   [ ] **Justificaci√≥n Metodol√≥gica**: Documentar decisiones t√©cnicas claves:
    *   Selecci√≥n de BERT/RoBERTa (vs GPT).
    *   Estrategia de Capas (Last 4 concatenation).
    *   Ajuste al Dominio (DAPT).
    *   Ortogonalizaci√≥n de Anclas (Gram-Schmidt/L√∂wdin).

#### Sub-fase 4.2: Visualizaci√≥n de Resultados
*   [ ] **Gr√°ficos Evolutivos High-End**:
    *   Serie de tiempo de *Semantic Drift* con eventos marcados.
    *   Heatmap de *Proyecciones Te√≥ricas* (Confianza, Inclusi√≥n, Riesgo) a trav√©s del tiempo.
    *   Evoluci√≥n de la *Entrop√≠a Sem√°ntica* (Complejidad del significado).
*   [ ] **Visualizaci√≥n del Subespacio**: Plot 2D/3D (PCA) de la trayectoria de la marca.

#### Sub-fase 4.3: Redacci√≥n y Discusi√≥n
*   [ ] **Interpretaci√≥n Sociol√≥gica**: Conectar los picos m√©tricos con eventos de la realidad (COVID, Bonos, Ca√≠das de sistema).
*   [ ] **Validaci√≥n Cruzada**: Contrastar hallazgos del modelo con la teor√≠a de frames propuesta.
*   [ ] **Conclusiones Finales**: Resumen de aportes y limitaciones.
*   [ ] **Refinamiento Estil√≠stico**: Asegurar tono acad√©mico neutral y riguroso en espa√±ol.

---

## 3. Pr√≥ximos Pasos Inmediatos (Sprint Actual)

1.  **Data Engineer**: Actualizar `Lisbeth` para soportar m√∫ltiples keywords (ej. "Yape", "Yapear").
2.  **Researcher**: Validar la lista de variantes de la marca a rastrear.
