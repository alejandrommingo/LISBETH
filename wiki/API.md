# 游댋 Referencia de API y CLI

La interacci칩n principal con LISBETH se realiza a trav칠s de su interfaz de l칤nea de comandos (CLI). El proyecto expone dos puntos de entrada principales: uno para NLP/An치lisis y otro espec칤fico para la recolecci칩n de noticias.

---

## 游눹 CLI Principal: `src/cli.py`

Este script orquesta las tareas de la **Fase 2 (NLP)**.

Uso general:
```bash
python src/cli.py [COMMAND] [ARGS]
```

### Comandos

#### `dapt` (Domain Adaptive Pretraining)
Re-entrena un modelo base (BERT/RoBERTa) con el corpus espec칤fico del dominio peruano.

*   **Argumentos**:
    *   `--data` (Requerido): Ruta al corpus de texto plano (`.txt`).
    *   `--model`: Modelo base de HuggingFace (Default: `PlanTL-GOB-ES/roberta-large-bne`).
    *   `--output`: Directorio donde guardar el modelo adaptado.
    *   `--epochs`: N칰mero de 칠pocas de entrenamiento (Default: 1).

*   **Ejemplo**:
    ```bash
    python src/cli.py dapt --data data/corpus_peru.txt --output models/ys-roberta
    ```

#### `extract`
Genera embeddings contextuales para una lista de keywords espec칤ficas.

*   **Argumentos**:
    *   `--data_dir`: Directorio conteniendo archivos CSV con las noticias.
    *   `--keywords`: Lista de palabras clave a vectorizar (ej. `Yape Yapear`).
    *   `--output`: Archivo de salida (formato Parquet recomendado).
    *   `--model`: Ruta o nombre del modelo a utilizar.

*   **Ejemplo**:
    ```bash
    python src/cli.py extract --keywords Yape Plin --output data/vectors.parquet
    ```

---

## 游닗 News Harvester CLI

Herramienta dedicada para la **Fase 1 (Recolecci칩n)**. Se ejecuta como un m칩dulo de Python.

Uso general:
```bash
python -m src.news_harvester [COMMAND] [ARGS]
```

### Comandos

#### `prototype`
Ejecuta el pipeline completo de recolecci칩n: Busca en GDELT -> Filtra -> Descarga HTML -> Procesa -> Guarda.

*   **Argumentos Clave**:
    *   `--keyword`: Palabras clave de b칰squeda.
    *   `--from`, `--to`: Rango de fechas (YYYY-MM-DD).
    *   `--media`: Filtro de medios (`all` o lista espec칤fica ej. `elcomercio`).
    *   `--format`: `csv` o `parquet`.
    *   `--skip-html`: Solo descarga metadatos, salta la descarga de cuerpos de noticias (칰til para pruebas r치pidas).

*   **Ejemplo Completo**:
    ```bash
    python -m src.news_harvester prototype \
      --keyword Yape \
      --from 2021-01-01 --to 2021-01-31 \
      --media all \
      --output data/enero_2021.csv
    ```

#### `fetch`
Solo consulta a la API de GDELT y devuelve metadatos crudos, sin descarga de HTML posterior autom치tica (a menos que se especifique flag). Utilizado para debugging o recolecci칩n ligera.

---

## 游닍 Estructura de M칩dulos (Python API)

Si deseas importar LISBETH como una librer칤a en tus scripts o notebooks, estas son las clases principales.

### `src.news_harvester`

*   **`collectors.fetch_articles`**: Funci칩n core que consulta GDELT con soporte para *daily chunking* (paginaci칩n diaria).
*   **`models.NewsRecord`**: Pydantic model que representa una noticia procesada y lista para an치lisis. Campos: `date`, `medium`, `title`, `body`, `url`.

### `src.nlp`

*   **`model.LisbethModel`**: Wrapper alrededor de `AutoModel` de HuggingFace. Maneja la tokenizaci칩n, movimiento a GPU y extracci칩n de capas ocultas (pooling strategy).
*   **`extract.extract_embeddings`**: Funci칩n de alto nivel que orquesta la lectura de datos, inferencia y guardado.

### `src.analysis`

*   Contiene l칩gica para la reducci칩n de dimensionalidad (SVD) y m칠tricas sem치nticas. (En desarrollo activo).
