# üè† LISBETH Wiki

Bienvenidos a la documentaci√≥n t√©cnica de **LISBETH** (Legitimacy & Identity Semantic BERT Embedding Time-series Harvester).

Este proyecto es parte del TFM **"De la billetera m√≥vil al actor social: An√°lisis computacional de la representaci√≥n medi√°tica de Yape en el Per√∫"**.

---

## üî≠ Visi√≥n General

**LISBETH** es un sistema h√≠brido que combina **Sociolog√≠a Digital** y **Procesamiento de Lenguaje Natural (NLP)** para analizar c√≥mo un producto financiero (Yape) se transforma en un fen√≥meno cultural. El sistema ingesta noticias hist√≥ricas, las procesa sem√°nticamente y modela su evoluci√≥n a lo largo del tiempo.

### Objetivos Clave
1.  **Recolecci√≥n Exhaustiva**: Recuperar el registro hist√≥rico completo de menciones en prensa (2016-2023).
2.  **Modelado Sem√°ntico**: Utilizar Modelos de Lenguaje (LLMs/Transformers) para capturar el significado contextual.
3.  **Sociolog√≠a Computacional**: Cuantificar conceptos abstractos como "legitimidad", "confianza" y "riesgo".

---

## üèóÔ∏è Arquitectura del Sistema

El flujo de trabajo se divide en 4 fases secuenciales:

```mermaid
graph TD
    subgraph Phase 1: Data Harvesting
        A[GDELT Project] -->|Raw Metadata| B(News Harvester)
        C[Google News] -->|Complementary| B
        B -->|Scraping & Cleaning| D[(Raw Corpus JSON/CSV)]
    end

    subgraph Phase 2: NLP Infrastructure
        D --> E[Domain Adaptation (DAPT)]
        E -->|Fine-tuned Roberta| F[Embedding Extraction]
        F -->|Subword Pooling| G[(Vector Database Parquet)]
    end

    subgraph Phase 3: Semantic Analysis
        G --> H[SVD / PCA Reduction]
        H --> I[Time-series Construction]
        I --> J[Metric Calculation]
        J -->|Semantic Drift / Entropy| K[Analytical Tables]
    end

    subgraph Phase 4: Reporting
        K --> L[Academic Notebook]
        L --> M[Paper / TFM Report]
    end
```

---

## üõ†Ô∏è Stack Tecnol√≥gico

### Core
*   **Lenguaje**: Python 3.12+
*   **Gesti√≥n de Dependencias**: `pip`, `venv`

### Data Engineering (Fase 1)
*   **Ingesta**: `requests`, `feedparser`, `trafilatura` (extracci√≥n de texto).
*   **Procesamiento**: `pandas`, `orjson` (JSON r√°pido).
*   **Fuentes**: API GDELT 2.0, Google News RSS.

### NLP & Machine Learning (Fase 2 & 3)
*   **Modelos**: Hugging Face Transformers (`roberta-large-bne`, `xlm-roberta`).
*   **Deep Learning**: PyTorch.
*   **√Ålgebra Lineal**: `scikit-learn` (PCA, SVD), `numpy`.

### An√°lisis y Visualizaci√≥n (Fase 4)
*   **Interactive**: Jupyter Lab.
*   **Plotting**: Matplotlib, Seaborn (para gr√°ficos est√°ticos de alta calidad).

---

## üìö Navegaci√≥n

*   **[Gu√≠a de Instalaci√≥n](Setup.md)**: Configura tu entorno de desarrollo.
*   **[Referencia API](API.md)**: Documentaci√≥n de comandos CLI y m√≥dulos internos.
*   **[Gu√≠a de Contribuci√≥n](Guia_Contribucion.md)**: Est√°ndares de c√≥digo y workflow.
