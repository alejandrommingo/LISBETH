{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 2 Validation Report (Final Execution)\n",
                "\n",
                "This notebook verifies the integrity of the data generated in Phase 2:\n",
                "1. **Baseline Occurrences**: `data/embeddings_baseline.parquet`\n",
                "2. **DAPT Occurrences**: `data/embeddings_dapt.parquet`\n",
                "3. **Baseline Anchors**: `data/anchors_baseline.parquet`\n",
                "4. **DAPT Anchors**: `data/anchors_dapt.parquet`\n",
                "\n",
                "It performs sanity checks (nulls, dimensions) and geometric comparison (PCA)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.decomposition import PCA\n",
                "import os\n",
                "\n",
                "# Output paths\n",
                "BASE_OCC_PATH = \"../data/embeddings_baseline.parquet\"\n",
                "DAPT_OCC_PATH = \"../data/embeddings_dapt.parquet\"\n",
                "BASE_ANC_PATH = \"../data/anchors_baseline.parquet\"\n",
                "DAPT_ANC_PATH = \"../data/anchors_dapt.parquet\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Occurrences Verification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def verify_dataset(path, name):\n",
                "    if not os.path.exists(path):\n",
                "        print(f\"❌ {name} not found at {path}\")\n",
                "        return None\n",
                "    \n",
                "    df = pd.read_parquet(path)\n",
                "    print(f\"✅ {name}: Loaded {len(df)} rows.\")\n",
                "    print(f\"   Columns: {df.columns.tolist()}\")\n",
                "    \n",
                "    # Check dimensions\n",
                "    if \"embedding_last4_concat\" in df.columns:\n",
                "        dim = len(df.iloc[0][\"embedding_last4_concat\"])\n",
                "        print(f\"   Last4 Dim: {dim}\")\n",
                "        \n",
                "    return df\n",
                "\n",
                "df_base = verify_dataset(BASE_OCC_PATH, \"Baseline Occs\")\n",
                "df_dapt = verify_dataset(DAPT_OCC_PATH, \"DAPT Occs\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Anchors Verification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_anc_base = verify_dataset(BASE_ANC_PATH, \"Baseline Anchors\")\n",
                "df_anc_dapt = verify_dataset(DAPT_ANC_PATH, \"DAPT Anchors\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Geometric Comparison (PCA: Baseline vs DAPT)\n",
                "Visualizing how the DAPT training shifted the embeddings space for Anchors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_comparison(df1, df2, label1, label2, vector_col=\"embedding_last4_concat\"):\n",
                "    if df1 is None or df2 is None: return\n",
                "    \n",
                "    vecs1 = np.stack(df1[vector_col].values)\n",
                "    vecs2 = np.stack(df2[vector_col].values)\n",
                "    all_vecs = np.vstack([vecs1, vecs2])\n",
                "    \n",
                "    pca = PCA(n_components=2)\n",
                "    coords = pca.fit_transform(all_vecs)\n",
                "    \n",
                "    c1 = coords[:len(vecs1)]\n",
                "    c2 = coords[len(vecs1):]\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    plt.scatter(c1[:,0], c1[:,1], alpha=0.5, label=label1, c='blue')\n",
                "    plt.scatter(c2[:,0], c2[:,1], alpha=0.5, label=label2, c='red')\n",
                "    plt.legend()\n",
                "    plt.title(\"PCA Projection: Baseline (Blue) vs DAPT (Red)\")\n",
                "    plt.show()\n",
                "\n",
                "plot_comparison(df_anc_base, df_anc_dapt, \"Baseline\", \"DAPT\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}