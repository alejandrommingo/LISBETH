{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Informe Comparativo de Cosecha de Datos: Phase 1 Improvements\n",
                "\n",
                "## Objetivo\n",
                "Comparar la calidad, volumen y cobertura de los datos recolectados **antes** de las mejoras de la Fase 1 (Old Data) vs. **después** de las mejoras (New Data).\n",
                "\n",
                "**Alcance Temporal:** 2019 - 2023 (Periodo solapado)\n",
                "**Datasets:**\n",
                "- **Old:** `data/yape_{YEAR}.csv`\n",
                "- **New:** `data/raw/yape_{YEAR}.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "import glob\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Configuración visual\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "plt.rcParams[\"figure.figsize\"] = (12, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Carga de Datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_dataset(base_path, label, years):\n",
                "    dfs = []\n",
                "    for year in years:\n",
                "        pattern = os.path.join(base_path, f\"yape_{year}*.csv\")\n",
                "        files = glob.glob(pattern)\n",
                "        for f in files:\n",
                "            if \"gap\" in f: continue # Skip gap files if any, to be fair\n",
                "            try:\n",
                "                # Intentar leer con detección automática de separador si falla\n",
                "                try:\n",
                "                    df = pd.read_csv(f)\n",
                "                except:\n",
                "                    df = pd.read_csv(f, sep=';')\n",
                "                \n",
                "                # Standardize columns\n",
                "                # Legacy fields sometimes use 'published_at' or 'newspaper'\n",
                "                if 'published_at' in df.columns:\n",
                "                    df.rename(columns={'published_at': 'publish_date'}, inplace=True)\n",
                "                if 'newspaper' in df.columns:\n",
                "                    df.rename(columns={'newspaper': 'domain'}, inplace=True)\n",
                "                if 'plain_text' in df.columns:\n",
                "                    df.rename(columns={'plain_text': 'text'}, inplace=True)\n",
                "\n",
                "                df['dataset'] = label\n",
                "                df['year_file'] = year\n",
                "                dfs.append(df)\n",
                "            except Exception as e:\n",
                "                print(f\"Error reading {f}: {e}\")\n",
                "    \n",
                "    if not dfs:\n",
                "        return pd.DataFrame()\n",
                "    \n",
                "    full_df = pd.concat(dfs, ignore_index=True)\n",
                "    return full_df\n",
                "\n",
                "REQ_YEARS = [2019, 2020, 2021, 2022, 2023]\n",
                "PROJECT_ROOT = Path(\"..\") # Assuming notebook is in 'notebooks/'\n",
                "\n",
                "old_df = load_dataset(PROJECT_ROOT / \"data\", \"Old (Legacy)\", REQ_YEARS)\n",
                "new_df = load_dataset(PROJECT_ROOT / \"data/raw\", \"New (Phase 1)\", REQ_YEARS)\n",
                "\n",
                "print(f\"Old Dataset Total Rows: {len(old_df)}\")\n",
                "print(f\"New Dataset Total Rows: {len(new_df)}\")\n",
                "\n",
                "combined_df = pd.concat([old_df, new_df], ignore_index=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Estandarización y Limpieza"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convertir fechas\n",
                "# Ensure publish_date is datetime\n",
                "combined_df['publish_date'] = pd.to_datetime(combined_df['publish_date'], errors='coerce', utc=True)\n",
                "combined_df['month_year'] = combined_df['publish_date'].dt.to_period('M')\n",
                "\n",
                "# Fill NA source_api for old data if missing\n",
                "if 'source_api' not in combined_df.columns:\n",
                "    combined_df['source_api'] = 'Unknown'\n",
                "combined_df['source_api'] = combined_df['source_api'].fillna('Legacy')\n",
                "\n",
                "combined_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Análisis Volumétrico"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 5))\n",
                "sns.countplot(data=combined_df, x='year_file', hue='dataset', palette='viridis')\n",
                "plt.title(\"Comparación de Volumen de Artículos por Año\")\n",
                "plt.ylabel(\"Número de Artículos\")\n",
                "plt.xlabel(\"Año\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribución mensual\n",
                "monthly_counts = combined_df.groupby(['month_year', 'dataset']).size().reset_index(name='count')\n",
                "monthly_counts['month_year'] = monthly_counts['month_year'].astype(str)\n",
                "\n",
                "plt.figure(figsize=(15, 6))\n",
                "sns.lineplot(data=monthly_counts, x='month_year', y='count', hue='dataset', marker='o')\n",
                "plt.xticks(rotation=90)\n",
                "plt.title(\"Tendencia Mensual de Recolección (2019-2023)\")\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Análisis de Contenido (Calidad)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calcular longitud del texto (si existe la columna de texto)\n",
                "# Posibles nombres: 'text', 'content', 'body', 'plain_text'\n",
                "text_col = 'text' if 'text' in combined_df.columns else 'content'\n",
                "if text_col not in combined_df.columns:\n",
                "    # Fallback search\n",
                "    for col in combined_df.columns:\n",
                "        if 'text' in col or 'content' in col:\n",
                "            text_col = col\n",
                "            break\n",
                "\n",
                "print(f\"Usando columna de texto: {text_col}\")\n",
                "\n",
                "combined_df['text_length'] = combined_df[text_col].astype(str).apply(len)\n",
                "\n",
                "# Plot distribución de longitud\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.boxplot(data=combined_df, x='dataset', y='text_length', showfliers=False)\n",
                "plt.title(\"Distribución de Longitud de Texto (Sin Outliers Extremos)\")\n",
                "plt.show()\n",
                "\n",
                "# Estadísticas descriptivas de longitud\n",
                "combined_df.groupby('dataset')['text_length'].describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Análisis de Fuentes y Dominios"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "top_domains_old = old_df['domain'].value_counts().head(10)\n",
                "top_domains_new = new_df['domain'].value_counts().head(10)\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "\n",
                "sns.barplot(x=top_domains_old.values, y=top_domains_old.index, ax=axes[0], palette=\"Blues_r\")\n",
                "axes[0].set_title(\"Top 10 Dominios - OLD Dataset\")\n",
                "\n",
                "sns.barplot(x=top_domains_new.values, y=top_domains_new.index, ax=axes[1], palette=\"Greens_r\")\n",
                "axes[1].set_title(\"Top 10 Dominios - NEW Dataset\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Overlap y Duplicidad\n",
                "¿Cuántos artículos coinciden por URL entre ambos datasets?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "common_urls = set(old_df['url']).intersection(set(new_df['url']))\n",
                "overlap_pct_old = len(common_urls) / len(old_df) * 100\n",
                "overlap_pct_new = len(common_urls) / len(new_df) * 100\n",
                "\n",
                "print(f\"Artículos comunes (match por URL): {len(common_urls)}\")\n",
                "print(f\"Porcentaje del OLD cubierto en NEW: {overlap_pct_old:.2f}%\")\n",
                "print(f\"Porcentaje del NEW presente en OLD: {overlap_pct_new:.2f}%\")\n",
                "\n",
                "# Venn Diagram concept (simple text)\n",
                "unique_old = len(old_df) - len(common_urls)\n",
                "unique_new = len(new_df) - len(common_urls)\n",
                "\n",
                "print(f\"\\nExclusivos en OLD: {unique_old}\")\n",
                "print(f\"Exclusivos en NEW: {unique_new}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Conclusión y Recomendación de Merge\n",
                "\n",
                "Basado en los datos anteriores, evaluamos si fusionar es beneficioso.\n",
                "\n",
                "**Criterios:**\n",
                "1. Si `Exclusivos en OLD` es alto (> 10-20%), vale la pena fusionar para no perder histórico.\n",
                "2. Si la calidad del texto en OLD es muy inferior (ver boxplot longitud), quizás sea mejor descartarlo o reprocesar sus URLs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulación de Merge Estratégico\n",
                "# Prioridad: NEW (Phase 1) porque tiene mejor limpieza de texto.\n",
                "# Relleno: Artículos de OLD que NO estén en NEW.\n",
                "\n",
                "merged_df = pd.concat([\n",
                "    new_df, \n",
                "    old_df[~old_df['url'].isin(new_df['url'])]\n",
                "], ignore_index=True)\n",
                "\n",
                "print(f\"Dataset Fusionado Potencial: {len(merged_df)} registros.\")\n",
                "print(f\"Ganancia Neta sobre NEW: {len(merged_df) - len(new_df)} registros.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}